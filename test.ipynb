{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install required packages\n",
    "!pip install dashvector dashscope\n",
    "!pip install transformers_stream_generator python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dashscope\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from dashscope import TextEmbedding\n",
    "from dashvector import Client, Doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get env variable from .env\n",
    "# please make sure DASHSCOPE_KEY is defined in .env\n",
    "load_dotenv()\n",
    "dashscope.api_key = 'sk-a6667deead1b47dd8d8b87d3906564c7'\n",
    "# initialize DashVector for embedding's indexing and searching\n",
    "dashvector_client = Client(api_key='sk-GUbWsxMunraDOjTenzU4oIVFwKJ7A6A7D6812471611EEA245A2FAE309D5DD')\n",
    "# define collection name\n",
    "collection_name = 'news_embeddings'\n",
    "\n",
    "# delete if already exist\n",
    "dashvector_client.delete(collection_name)\n",
    "# create a collection with embedding size of 1536\n",
    "rsp = dashvector_client.create(collection_name, 1536)\n",
    "collection = dashvector_client.get(collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_from_dir(path, size):\n",
    "    # prepare the data from a file folder in order to upsert to DashVector with a reasonable doc's size.\n",
    "    batch_docs = []\n",
    "    for file in os.listdir(path):\n",
    "        if file == '.ipynb_checkpoints':\n",
    "           continue\n",
    "        else:\n",
    "            with open(path + '/' + file, 'r', encoding='utf-8') as f:\n",
    "               batch_docs.append(f.read())\n",
    "               if len(batch_docs) == size:\n",
    "                   yield batch_docs[:]\n",
    "                   batch_docs.clear()\n",
    "\n",
    "    if batch_docs:\n",
    "        yield batch_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_from_file(path, size):\n",
    "    # prepare the data from file in order to upsert to DashVector with a reasonable doc's size.\n",
    "    batch_docs = []\n",
    "    chunk_size = 12\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        doc = ''\n",
    "        count = 0\n",
    "        for line in f:\n",
    "            if count < chunk_size and line.strip() != '':\n",
    "                doc += line\n",
    "                count += 1\n",
    "            if count == chunk_size:\n",
    "                batch_docs.append(doc)\n",
    "                if len(batch_docs) == size:\n",
    "                    yield batch_docs[:]\n",
    "                    batch_docs.clear()\n",
    "                doc = ''\n",
    "                count = 0\n",
    "\n",
    "    if batch_docs:\n",
    "        yield batch_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(docs):\n",
    "    # create embeddings via DashScope's TextEmbedding model API\n",
    "    rsp = TextEmbedding.call(model=TextEmbedding.Models.text_embedding_v1,\n",
    "                             input=docs)\n",
    "    embeddings = [record['embedding'] for record in rsp.output['embeddings']]\n",
    "    return embeddings if isinstance(docs, list) else embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  !git clone https://github.com/jsonzhuwei/gasgootest.git\n",
    "id = 0\n",
    "dir_name = 'gasgootest/companytext'\n",
    "\n",
    "# indexing the raw docs with index to DashVector\n",
    "collection = dashvector_client.get(collection_name)\n",
    "\n",
    "# embedding api max batch size\n",
    "batch_size = 4\n",
    "\n",
    "for news in list(prepare_data_from_dir(dir_name, batch_size)):\n",
    "    ids = [id + i for i, _ in enumerate(news)]\n",
    "    id += len(news)\n",
    "    # generate embedding from raw docs\n",
    "    vectors = generate_embeddings(news)\n",
    "    # upsert and index\n",
    "    ret = collection.upsert(\n",
    "        [\n",
    "            Doc(id=str(id), vector=vector, fields={\"raw\": doc})\n",
    "            for id, doc, vector in zip(ids, news, vectors)\n",
    "        ]\n",
    "    )\n",
    "    print(ret)\n",
    "\n",
    "# check the collection status\n",
    "collection = dashvector_client.get(collection_name)\n",
    "rsp = collection.stats()\n",
    "print(rsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_relevant_context(question, topk=3, client=dashvector_client):\n",
    "    # query and recall the relevant information\n",
    "    collection = client.get(collection_name)\n",
    "\n",
    "    # recall the top k similarity results from DashVector\n",
    "    rsp = collection.query(generate_embeddings(question), output_fields=['raw'],\n",
    "                           topk=topk)\n",
    "    return \"\".join([item.fields['raw'] for item in rsp.output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query the top 1 results\n",
    "question = '注册地址在上海的有哪几家公司？'\n",
    "context = search_relevant_context(question, topk=3)\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize qwen 7B model\n",
    "from modelscope import AutoModelForCausalLM, AutoTokenizer\n",
    "from modelscope import GenerationConfig\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"qwen/Qwen-7B-Chat\", revision = 'v1.0.5',trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"qwen/Qwen-7B-Chat\", revision = 'v1.0.5',device_map=\"auto\", trust_remote_code=True, fp16=True).eval()\n",
    "model.generation_config = GenerationConfig.from_pretrained(\"Qwen/Qwen-7B-Chat\",revision = 'v1.0.5', trust_remote_code=True) # 可指定不同的生成长度、top_p等相关超参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a prompt template for the vectorDB-enhanced LLM generation\n",
    "def answer_question(question, context):\n",
    "    prompt = f'''请基于```内的内容回答问题。\"\n",
    "\t```\n",
    "\t{context}\n",
    "\t```\n",
    "\t我的问题是：{question}？。\n",
    "    '''\n",
    "    history = None\n",
    "    print(prompt)\n",
    "    response, history = model.chat(tokenizer, prompt, history=None)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the case on plain LLM without vectorDB enhancement\n",
    "question = '注册地址在上海的有哪几家公司'\n",
    "answer = answer_question(question, '')\n",
    "print(f'question: {question}\\n' f'answer: {answer}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the case with knowledge\n",
    "context = search_relevant_context(question, topk=3)\n",
    "answer = answer_question(question, context)\n",
    "print(f'question: {question}\\n' f'answer: {answer}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
